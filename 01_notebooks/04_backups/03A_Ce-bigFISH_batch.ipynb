{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Ce-bigFISH: image analysis toolkit in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 240819\n",
    "\n",
    "#### Add conditional/interactive statement to choose between total abundance (whole embryo mask) or single cell detection (up to 4-cell stage embryos)\n",
    "\n",
    "#### Rotate embryos according to body axis. Needed for the density plots, single cell detection and for the DV2PNG notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify where the directory of the data\n",
    "local_download_directory = '/pl/active/onishimura_lab/PROJECTS/naly/bigfish/02_DG_quantification/DG5919_smFISH/240702_DG5919_lin-41_set-3/2-cell'\n",
    "\n",
    "#specify the molecules in each channel\n",
    "Cy5 = \"set-3_mRNA\" #(asymmetrical control)\n",
    "mCherry = \"lin-41_mRNA\" #(query mRNA)\n",
    "FITC = \"nothing\" #(ignore in this case) This is where protein markers usually go.\n",
    "DAPI = \"DAPI\"\n",
    "brightfield = \"brightfield\"\n",
    "\n",
    "#info about your microscope\n",
    "wavelength_cy5 = 670 # Cy5 emmision peak in nm\n",
    "wavelength_mCherry = 610  # mCherry emmision peak in nm\n",
    "na = 1.42  # numerical aperture of microscope\n",
    "refractive_index_medium = 1.515 # oil refractive index\n",
    "\n",
    "voxel_size = (1448, 450, 450)   # Microscope pixel size Z,Y,X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "#import packages:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tifffile\n",
    "import bigfish\n",
    "import bigfish.stack as stack\n",
    "import bigfish.plot as plot\n",
    "import bigfish.multistack as multistack\n",
    "import bigfish.detection as detection\n",
    "\n",
    "import cellpose\n",
    "from cellpose import models\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import square, dilation, erosion\n",
    "from skimage import measure, morphology\n",
    "\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/pl/active/onishimura_lab/PROJECTS/naly/bigfish/02_DG_quantification/DG5919_smFISH/240702_DG5919_lin-41_set-3/2 cell/input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m folder_name \u001b[38;5;241m=\u001b[39m local_download_directory\u001b[38;5;241m.\u001b[39msplit(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get a list of subdirectories within local_download_directory\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m subdirectories \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ipynb_checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_directory, item))]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Iterate through the subdirectories and store their path in a list\u001b[39;00m\n\u001b[1;32m     10\u001b[0m subdirectory_paths \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/pl/active/onishimura_lab/PROJECTS/naly/bigfish/02_DG_quantification/DG5919_smFISH/240702_DG5919_lin-41_set-3/2 cell/input'"
     ]
    }
   ],
   "source": [
    "# Specify where the data will be stored\n",
    "input_directory = os.path.join(local_download_directory, 'input')\n",
    "output_directory = os.path.join(local_download_directory, 'output')\n",
    "folder_name = local_download_directory.split(os.path.sep)[-1]\n",
    "\n",
    "# Get a list of subdirectories within local_download_directory\n",
    "subdirectories = [item for item in sorted(os.listdir(input_directory)) if item != '.ipynb_checkpoints' and os.path.isdir(os.path.join(input_directory, item))]\n",
    "\n",
    "# Iterate through the subdirectories and store their path in a list\n",
    "subdirectory_paths = []\n",
    "for subdirectory in subdirectories:\n",
    "    subdirectory_path = os.path.join(input_directory, subdirectory)\n",
    "    subdirectory_paths.append(subdirectory_path)\n",
    "\n",
    "# Initialize lists for image stacks and file paths\n",
    "all_image_stacks = []\n",
    "all_files = []\n",
    "for subdirectory_path in subdirectory_paths:\n",
    "    files = [os.path.join(subdirectory_path, item) for item in os.listdir(subdirectory_path)]\n",
    "    \n",
    "    # Check if exactly 2 files with the specified names are present\n",
    "    if len(files) == 2 and any(file.endswith(\"R3D_REF.dv\") for file in files) and any(file.endswith(\"R3D.dv\") for file in files):\n",
    "        files = sorted(files)\n",
    "        all_files.append(files)\n",
    "        \n",
    "        # Store all image stacks in a list\n",
    "        subdirectory_image_stacks = []\n",
    "        for file_path in files:\n",
    "            image_stack = stack.read_dv(file_path, sanity_check=False)\n",
    "            \n",
    "            # Convert the image stack to np.uint16 format as it's being parsed\n",
    "            image_stack = image_stack.astype(np.uint16)\n",
    "            subdirectory_image_stacks.append(image_stack)\n",
    "        \n",
    "        all_image_stacks.append(subdirectory_image_stacks)\n",
    "        \n",
    "    else:\n",
    "        print(f\"corrupted: {subdirectory_path}\")\n",
    "        # Copy the entire corrupted directory to the 'corrupted_files' directory\n",
    "        corrupted_path = os.path.join(local_download_directory, 'corrupted_files')\n",
    "        corrupted_subdirectory = os.path.basename(subdirectory_path)\n",
    "        corrupted_destination = os.path.join(corrupted_path, corrupted_subdirectory)\n",
    "        shutil.move(subdirectory_path, corrupted_destination)\n",
    "        continue\n",
    "\n",
    "# Now, all_image_stacks contains the image data from all the .dv files, organized by subdirectory.\n",
    "print(f'Images read: {len(all_image_stacks)}')\n",
    "\n",
    "# Initialize the list for image names\n",
    "image_names = []\n",
    "\n",
    "# Process all files to extract image names\n",
    "for file_pair in all_files:\n",
    "    for file_path in file_pair:\n",
    "        # Extract the filename without extension\n",
    "        filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        # Extract the part before the last underscore\n",
    "        image_name = filename.rsplit('_', 0)[0]\n",
    "        # Add the image_name to the list if it's not already present and does not end with '_REF'\n",
    "        if image_name not in image_names and not image_name.endswith('_REF'):\n",
    "            image_names.append(image_name)\n",
    "\n",
    "# Print the list of image names\n",
    "print(image_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_colors, bf, Cy5, mCherry, FITC, DAPI, subdirectory_path):\n",
    "# List of channel names and their corresponding images\n",
    "    channels = [Cy5, mCherry, FITC, DAPI, brightfield]\n",
    "    titles = [Cy5, mCherry, FITC, DAPI, brightfield]\n",
    "    plot_info = f\"Image Color Shape: {image_colors.shape}\\nBF Shape: {bf.shape}\"\n",
    "    images = [\n",
    "        np.max(image_colors[0, :, :, :], axis=0) if image_colors[0] is not None and Cy5 else None,\n",
    "        np.max(image_colors[1, :, :, :], axis=0) if image_colors[1] is not None and mCherry else None,\n",
    "        np.max(image_colors[2, :, :, :], axis=0) if image_colors[2] is not None and FITC else None,\n",
    "        np.max(image_colors[3, :, :, :], axis=0) if image_colors[3] is not None and DAPI else None,\n",
    "        bf if brightfield is not None else None\n",
    "    ]\n",
    "    \n",
    "    # Filter out None entries\n",
    "    filtered_images = [(img, title) for img, title in zip(images, titles) if img is not None]\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(filtered_images), figsize=(6 * len(filtered_images), 8))\n",
    "\n",
    "    # Ensure ax is always iterable, even if there's only one plot\n",
    "    if len(filtered_images) == 1:\n",
    "        ax = [ax]\n",
    "\n",
    "    for i, (img, title) in enumerate(filtered_images):\n",
    "        ax[i].imshow(img)\n",
    "        ax[i].set_title(title, size=20)\n",
    "        ax[i].axis('off')\n",
    "        \n",
    "\n",
    "    # Adjust layout if necessary\n",
    "    plt.tight_layout()\n",
    "    ax[i].text(0.5, 0.5, plot_info, ha='center', va='center', fontsize=12, color='black', bbox=dict(facecolor='lightgray'))\n",
    "    ax[i].axis('off')  # Turn off the axis for this colum\n",
    "\n",
    "    \n",
    "image_output_directories = []\n",
    "# Now iterate through all_image_stacks and call plot with the appropriate arguments\n",
    "\n",
    "for i, stack_image in enumerate(all_image_stacks):\n",
    "    #if i != 1:\n",
    "        image_colors = all_image_stacks[i][0]\n",
    "        bf = all_image_stacks[i][1]\n",
    "        plot_image(image_colors, bf, Cy5, mCherry, FITC, DAPI, subdirectory_paths[i])\n",
    "        subdirectory = subdirectories[i]\n",
    "\n",
    "        # Create image_output_directory. This is where all the output will end up going. \n",
    "        image_output_directory = os.path.join(output_directory, subdirectory)\n",
    "        os.makedirs(image_output_directory, exist_ok=True)\n",
    "        image_output_directories.append(image_output_directory)\n",
    "        \n",
    "        # Generate filename with subdirectory\n",
    "        image_colors_filename = os.path.join(image_output_directory, f\"{subdirectory}_image_colors.png\")\n",
    "    \n",
    "        plt.savefig(image_colors_filename)\n",
    "        plt.show()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions used for segmentation\n",
    "def is_nucleus_in_cytosol(mask_n, mask_c):\n",
    "    mask_n[mask_n>1]=1\n",
    "    mask_c[mask_c>1]=1\n",
    "    size_mask_n = np.count_nonzero(mask_n)\n",
    "    size_mask_c = np.count_nonzero(mask_c)\n",
    "    min_size =np.min( (size_mask_n,size_mask_c) )\n",
    "    mask_combined =  mask_n + mask_c\n",
    "    sum_mask = np.count_nonzero(mask_combined[mask_combined==2])\n",
    "    if (sum_mask> min_size*0.8) and (min_size>200): # the element is inside if the two masks overlap over the 80% of the smaller mask.\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def remove_lonely_masks(masks_0, masks_1,is_nuc=None):\n",
    "    n_mask_0 = np.max(masks_0)\n",
    "    n_mask_1 = np.max(masks_1)\n",
    "    if (n_mask_0>0) and (n_mask_1>0):\n",
    "        for ind_0 in range(1,n_mask_0+1):\n",
    "            tested_mask_0 = erosion(np.where(masks_0 == ind_0, 1, 0))\n",
    "            array_paired= np.zeros(n_mask_1)\n",
    "            for ind_1 in range(1,n_mask_1+1):\n",
    "                tested_mask_1 = erosion(np.where(masks_1 == ind_1, 1, 0))\n",
    "                array_paired[ind_1-1] = is_nucleus_in_cytosol(tested_mask_1, tested_mask_0)\n",
    "                if (is_nuc =='nuc') and (np.count_nonzero(tested_mask_0) > np.count_nonzero(tested_mask_1) ):\n",
    "                    # condition that rejects images with nucleus bigger than the cytosol\n",
    "                    array_paired[ind_1-1] = 0\n",
    "                elif (is_nuc is None ) and (np.count_nonzero(tested_mask_1) > np.count_nonzero(tested_mask_0) ):\n",
    "                    array_paired[ind_1-1] = 0\n",
    "            if any (array_paired) == False: # If the cytosol is not associated with any mask.\n",
    "                masks_0 = np.where(masks_0 == ind_0, 0, masks_0)\n",
    "            masks_with_pairs = masks_0\n",
    "    else:\n",
    "        masks_with_pairs = np.zeros_like(masks_0)\n",
    "    return masks_with_pairs\n",
    "\n",
    "def matching_masks(masks_cyto, masks_nuclei):\n",
    "    n_mask_cyto = np.max(masks_cyto)\n",
    "    n_mask_nuc = np.max(masks_nuclei)\n",
    "    new_masks_nuclei = np.zeros_like(masks_cyto)\n",
    "    reordered_mask_nuclei = np.zeros_like(masks_cyto)\n",
    "    if (n_mask_cyto>0) and (n_mask_nuc>0):\n",
    "        for mc in range(1,n_mask_cyto+1):\n",
    "            tested_mask_cyto = np.where(masks_cyto == mc, 1, 0)\n",
    "            for mn in range(1,n_mask_nuc+1):\n",
    "                mask_paired = False\n",
    "                tested_mask_nuc = np.where(masks_nuclei == mn, 1, 0)\n",
    "                mask_paired = is_nucleus_in_cytosol(tested_mask_nuc, tested_mask_cyto)\n",
    "                if mask_paired == True:\n",
    "                    if np.count_nonzero(new_masks_nuclei) ==0:\n",
    "                        new_masks_nuclei = np.where(masks_nuclei == mn, -mc, masks_nuclei)\n",
    "                    else:\n",
    "                        new_masks_nuclei = np.where(new_masks_nuclei == mn, -mc, new_masks_nuclei)\n",
    "            reordered_mask_nuclei = np.absolute(new_masks_nuclei)\n",
    "    return reordered_mask_nuclei\n",
    "\n",
    "def remove_extreme_values(image,min_percentile=0.1, max_percentile=99.5):\n",
    "    max_val = np.percentile(image, max_percentile)\n",
    "    min_val = np.percentile(image, min_percentile)\n",
    "    image [image < min_val] = min_val\n",
    "    image [image > max_val] = max_val\n",
    "    return image\n",
    "\n",
    "def metric_max_cells_and_area( masks):\n",
    "    n_masks = np.max(masks)\n",
    "    if n_masks > 1: # detecting if more than 1 mask are detected per cell\n",
    "        size_mask = []\n",
    "        for nm in range (1, n_masks+1): # iterating for each mask in a given cell. The mask has values from 0 for background, to int n, where n is the number of detected masks.\n",
    "            approximated_radius = np.sqrt(np.sum(masks == nm)/np.pi)  # a=  pi r2\n",
    "            size_mask.append(approximated_radius) #np.sum(masks == nm)) # creating a list with the size of each mask\n",
    "        size_masks_array = np.array(size_mask)\n",
    "        metric = np.mean(size_masks_array).astype(int) * n_masks\n",
    "    elif n_masks == 1: # do nothing if only a single mask is detected per image.\n",
    "        approximated_radius = np.sqrt(np.sum(masks == 1)/np.pi) \n",
    "        metric = approximated_radius.astype(int)\n",
    "    else:  # return zero if no mask are detected\n",
    "        metric = 0  \n",
    "    return metric   \n",
    "\n",
    "def nuclear_segmentation(image_nuclei):\n",
    "    MIN_CELL_SIZE = 1000\n",
    "    list_masks_nuclei = []\n",
    "    list_thresholds = np.arange(0.7,0.95, 0.05)\n",
    "    array_number_detected_masks = np.zeros(len(list_thresholds))\n",
    "    for i,tested_ts in enumerate(list_thresholds):\n",
    "        image_nuclei_binary = image_nuclei.copy()\n",
    "        max_value_image = np.max(image_nuclei_binary)\n",
    "        image_nuclei_binary[image_nuclei_binary < max_value_image*tested_ts] = 0\n",
    "        image_nuclei_binary[image_nuclei_binary > max_value_image*tested_ts] = 1\n",
    "        labels = measure.label(image_nuclei_binary)\n",
    "        filtered_labels = morphology.remove_small_objects(labels, min_size=MIN_CELL_SIZE)\n",
    "        unique_filtered_labels = np.unique(filtered_labels)\n",
    "        tested_masks_nuclei = np.zeros_like(filtered_labels)\n",
    "        for idx, old_label in enumerate(unique_filtered_labels):\n",
    "            tested_masks_nuclei[filtered_labels == old_label] = idx\n",
    "        list_masks_nuclei.append(tested_masks_nuclei)\n",
    "        array_number_detected_masks[i]= metric_max_cells_and_area( tested_masks_nuclei) \n",
    "    selected_index = np.argmax(array_number_detected_masks)\n",
    "    masks_nuclei = list_masks_nuclei [selected_index]\n",
    "    return masks_nuclei\n",
    "\n",
    "def cytosol_segmentation(image_cytosol,second_image_cytosol,cytosol_diameter):\n",
    "    flow_ts=1\n",
    "    MIN_CELL_SIZE = 1000\n",
    "    model = models.Cellpose(gpu=True, model_type='cyto2') # model_type='cyto', 'cyto2' or model_type='nuclei'\n",
    "    if not (second_image_cytosol is None):\n",
    "        merged_image_cytosol = np.concatenate((image_cytosol[:, :, np.newaxis], second_image_cytosol[:, :, np.newaxis]), axis=2)\n",
    "        masks_cytosol_unfiltered = model.eval(merged_image_cytosol, diameter=cytosol_diameter, flow_threshold=flow_ts, channels=[0,1])[0]\n",
    "    else:\n",
    "        masks_cytosol_unfiltered = model.eval(image_cytosol, diameter=cytosol_diameter, flow_threshold=flow_ts, channels=[0,0])[0]\n",
    "    filtered_cyto = morphology.remove_small_objects(masks_cytosol_unfiltered, min_size=MIN_CELL_SIZE)\n",
    "    unique_filtered_cyto = np.unique(filtered_cyto)\n",
    "    masks_cytosol = np.zeros_like(filtered_cyto)\n",
    "    for idx, old_label in enumerate(unique_filtered_cyto):\n",
    "        masks_cytosol[filtered_cyto == old_label] = idx\n",
    "    return masks_cytosol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_optimization(image_cytosol,image_nuclei,cytosol_diameter,second_image_cytosol=None):\n",
    "    # Cytosol segmentation\n",
    "    masks_cytosol =cytosol_segmentation(image_cytosol,second_image_cytosol,cytosol_diameter)\n",
    "    # Nuclear segmentation\n",
    "    masks_nuclei = nuclear_segmentation(image_nuclei)\n",
    "    # reordering nuclei masks\n",
    "    masks_nuclei = matching_masks(masks_cytosol,masks_nuclei)\n",
    "    # remove masks without nuclei\n",
    "    masks_nuclei= remove_lonely_masks(masks_0=masks_nuclei , masks_1=masks_cytosol,is_nuc='nuc')\n",
    "    masks_cytosol= remove_lonely_masks(masks_0=masks_cytosol , masks_1=masks_nuclei)\n",
    "    # calculate size of masks\n",
    "    number_masks_cyto = np.max(masks_cytosol)\n",
    "    list_masks_cyto_sizes =[]\n",
    "    for i in range (1, number_masks_cyto+1):\n",
    "        list_masks_cyto_sizes.append(len(masks_cytosol[masks_cytosol==i]) )\n",
    "    number_masks_nuc = np.max(masks_nuclei)\n",
    "    list_masks_nuc_sizes =[]\n",
    "    for i in range (1, number_masks_nuc+1):\n",
    "        list_masks_nuc_sizes.append(len(masks_nuclei[masks_nuclei==i]) )\n",
    "    return masks_nuclei, masks_cytosol,list_masks_nuc_sizes, list_masks_cyto_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes used to segment the nucleus and the cytosol\n",
    "def segmentation(image_cytosol,image_nuclei, second_image_cytosol=None):\n",
    "    # removing outliers in image\n",
    "    image_cytosol = remove_extreme_values(image=image_cytosol,min_percentile=0.1, max_percentile=99.5)\n",
    "    if not (second_image_cytosol is None):\n",
    "        second_image_cytosol = remove_extreme_values(image=second_image_cytosol,min_percentile=0.1, max_percentile=99.5)\n",
    "    image_nuclei = remove_extreme_values(image=image_nuclei,min_percentile=0.1, max_percentile=99.5)\n",
    "    # Optimization segmentation\n",
    "    list_masks_nuclei = []\n",
    "    list_masks_cytosol=[]\n",
    "    list_masks_nuc_sizes =[]\n",
    "    list_masks_cyto_sizes=[]\n",
    "    list_flow_thresholds = np.arange(40, 200, 10)\n",
    "    array_number_detected_masks = np.zeros(len(list_flow_thresholds))\n",
    "    for i,tested_ts in enumerate(list_flow_thresholds):\n",
    "        tested_masks_nuclei, tested_masks_cytosol, tested_list_masks_nuc_sizes, tested_list_masks_cyto_sizes = segmentation_optimization(image_cytosol,image_nuclei,cytosol_diameter=tested_ts,second_image_cytosol=second_image_cytosol)\n",
    "        list_masks_nuclei.append(tested_masks_nuclei)\n",
    "        list_masks_cytosol.append(tested_masks_cytosol)\n",
    "        list_masks_nuc_sizes.append(tested_list_masks_nuc_sizes)\n",
    "        list_masks_cyto_sizes.append(tested_list_masks_cyto_sizes)\n",
    "        array_number_detected_masks[i]= metric_max_cells_and_area( tested_masks_cytosol) + metric_max_cells_and_area( tested_masks_nuclei)\n",
    "    selected_index = np.argmax(array_number_detected_masks)\n",
    "    masks_nuclei = list_masks_nuclei [selected_index]\n",
    "    masks_cytosol = list_masks_cytosol [selected_index]\n",
    "    masks_nuc_sizes = list_masks_nuc_sizes[selected_index]\n",
    "    masks_cyto_sizes = list_masks_cyto_sizes[selected_index]\n",
    "    \n",
    "        # Plotting\n",
    "    color_map = 'Greys_r'\n",
    "    fig, ax = plt.subplots(1,4, figsize=(14, 4))\n",
    "    # Plotting the heatmap of a section in the image\n",
    "    ax[0].imshow(image_nuclei,cmap=color_map)\n",
    "    ax[1].imshow(masks_nuclei,cmap=color_map)\n",
    "    ax[2].imshow(image_cytosol,cmap=color_map)\n",
    "    ax[3].imshow(masks_cytosol,cmap=color_map)\n",
    "    ax[0].set(title='DAPI'); ax[0].axis('off');ax[0].grid(False)\n",
    "    ax[1].set(title='mask nuclei'); ax[1].axis('off');ax[1].grid(False)\n",
    "    ax[2].set(title='brightfield'); ax[2].axis('off');ax[2].grid(False)\n",
    "    ax[3].set(title='mask cytosol'); ax[3].axis('off');ax[3].grid(False)\n",
    "\n",
    "    \n",
    "    return masks_cytosol, masks_nuclei, masks_cyto_sizes, masks_nuc_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run segmentation functions\n",
    "\n",
    "# Now iterate through all_image_stacks and call plot with the appropriate arguments\n",
    "list_all_masks_nuc =[]\n",
    "list_all_masks_cyto =[]\n",
    "list_all_nuc_size =[]\n",
    "list_all_cyto_size=[]\n",
    "\n",
    "\n",
    "# Iterate through all_image_stacks\n",
    "for i, stack_image in enumerate(all_image_stacks):\n",
    "    image_colors = all_image_stacks[i][0]\n",
    "    image_nuclei = np.max(image_colors[3, :, :, :], axis=0)\n",
    "    image_cytosol = all_image_stacks[i][1]\n",
    "    second_image_cytosol = np.max(image_colors[3,:,:,:],axis=0 )\n",
    "    masks_cytosol, masks_nuclei,list_masks_cyto_sizes, list_masks_nuc_sizes = segmentation(image_cytosol,image_nuclei,second_image_cytosol)\n",
    "    list_all_masks_nuc.append(masks_nuclei)\n",
    "    list_all_masks_cyto.append(masks_cytosol)\n",
    "    list_all_nuc_size.append(list_masks_nuc_sizes)\n",
    "    list_all_cyto_size.append(list_masks_cyto_sizes)\n",
    "    \n",
    "    image_output_directory = image_output_directories[i]\n",
    "    segmentation_filename = os.path.join(image_output_directory, f\"{subdirectories[i]}_segmentation.png\")\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(segmentation_filename)\n",
    "\n",
    "# Display the last segmentation plot (optional)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Spot detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codes used for spot detection\n",
    "# Note: spot radius = Point Spread Function (PSF)\n",
    "\n",
    "def spot_detection(rna, voxel_size, spot_radius, masks_cytosol, image_output_directory, subdirectory):\n",
    "    spots, threshold = detection.detect_spots(\n",
    "        images=rna,\n",
    "        return_threshold=True,\n",
    "        voxel_size=voxel_size,\n",
    "        spot_radius=spot_radius) \n",
    "\n",
    "    spot_radius_px = detection.get_object_radius_pixel(\n",
    "        voxel_size_nm=voxel_size,\n",
    "        object_radius_nm=spot_radius,\n",
    "        ndim=3) \n",
    "\n",
    "    # LoG filter\n",
    "    rna_log = stack.log_filter(rna, sigma=spot_radius_px)\n",
    "\n",
    "    # local maximum detection\n",
    "    mask = detection.local_maximum_detection(rna_log, min_distance=spot_radius_px)\n",
    "\n",
    "    # thresholding\n",
    "    threshold = detection.automated_threshold_setting(rna_log, mask)\n",
    "    spots, _ = detection.spots_thresholding(rna_log, mask, threshold)\n",
    "\n",
    "    # Decompose regions by simulating as many spots as possible until we match the original region intensity.\n",
    "    spots_post_decomposition, dense_regions, reference_spot = detection.decompose_dense(\n",
    "        image=rna,\n",
    "        spots=spots,\n",
    "        voxel_size=voxel_size,\n",
    "        spot_radius=spot_radius,\n",
    "        alpha=0.7,  # alpha impacts the number of spots per candidate region\n",
    "        beta=1,  # beta impacts the number of candidate regions to decompose\n",
    "        gamma=5)  # gamma the filtering step to denoise the image\n",
    "\n",
    "    # Define clusters\n",
    "    spots_post_clustering, clusters = detection.detect_clusters(\n",
    "        spots=spots_post_decomposition,\n",
    "        voxel_size=voxel_size,\n",
    "        radius=626,  # 626\n",
    "        nb_min_spots=4)\n",
    "\n",
    "    # Plotting\n",
    "    print(f\"{rna_channel} detection\")\n",
    "    print(f\" threshold: {threshold}\")\n",
    "    print(\"\\r spots: {0}\".format(spots_post_clustering.shape[0]))\n",
    "    print(\"\\r clusters: {0}\".format(clusters.shape[0]))\n",
    "\n",
    "    # Elbow plot\n",
    "    threshold_filename = os.path.join(image_output_directory, subdirectory + '_' + rna_channel +  '_threshold')\n",
    "    plot.plot_elbow(\n",
    "        images=rna,\n",
    "        voxel_size=voxel_size,\n",
    "        spot_radius=spot_radius,\n",
    "        size_axes=8,\n",
    "        framesize=(5, 3),\n",
    "        title=(f\"{rna_channel} detection threshold\"),\n",
    "        size_title=12,\n",
    "        path_output=threshold_filename,\n",
    "        show=True  # Set show to False to prevent displaying the plot\n",
    "    )\n",
    "\n",
    "    # Save the plots in the results folder\n",
    "    detection_filename = os.path.join(image_output_directory, subdirectory + '_' + rna_channel + '_detection')\n",
    "    plot.plot_detection(\n",
    "        image=np.max(rna, axis=0), \n",
    "        spots=[spots_post_decomposition, clusters[:, :3]],\n",
    "        shape=[\"circle\", \"polygon\"],\n",
    "        radius=[1.5, 4],\n",
    "        color=[\"red\", \"blue\"],\n",
    "        linewidth=[1, 2],\n",
    "        fill=[False, True],\n",
    "        contrast=True,\n",
    "        framesize=(4, 4),\n",
    "        title=(f\"{rna_channel} detection\"),\n",
    "        path_output=detection_filename,\n",
    "        show=True\n",
    "    )\n",
    "\n",
    "    # Separating and counting the spots in each cell\n",
    "    number_masks_cyto = np.max(masks_cytosol)\n",
    "    list_spots_in_each_cell = []\n",
    "    list_clusters_in_each_cell = []\n",
    "    for i in range(1, number_masks_cyto + 1):\n",
    "        temp_cyto_mask = np.zeros_like(masks_cytosol)\n",
    "        temp_cyto_mask[masks_cytosol == i] = i\n",
    "        spots_in_region, _ = multistack.identify_objects_in_region(mask=temp_cyto_mask, coord=spots_post_clustering[:,:3], ndim=3)\n",
    "        clusters_in_region, _ = multistack.identify_objects_in_region(mask=temp_cyto_mask, coord=clusters[:,:3], ndim=3)\n",
    "        list_spots_in_each_cell.append(len(spots_in_region))\n",
    "        list_clusters_in_each_cell.append(len(clusters_in_region))\n",
    "        del spots_in_region, clusters_in_region\n",
    "\n",
    "    return spots_post_clustering, clusters, list_spots_in_each_cell, list_clusters_in_each_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSF calculator \n",
    "wavelength_mCherry = 610  # wavelength in nm -> specified above\n",
    "wavelength_cy5 = 670  # wavelength in nm -> specified above\n",
    "na = 1.42  # numerical aperture -> specified above\n",
    "refractive_index_medium = 1.515  # refractive index of imaging medium (oil)\n",
    "\n",
    "\n",
    "# #ch1 - mCherry channel\n",
    "# Calculate lateral PSF\n",
    "fwhm_xy = 0.61 * wavelength_mCherry / na\n",
    "# Calculate axial PSF\n",
    "fwhm_z = 2 * refractive_index_medium * wavelength_mCherry / na**2\n",
    "# Print the result\n",
    "print(f\"Lateral (xy) PSF: {fwhm_xy} nm\")\n",
    "print(f\"Axial (z) PSF with 60x oil objective: {fwhm_z} nm\")\n",
    "\n",
    "\"/n\"\n",
    "\n",
    "# #ch0 - Cy5 channel\n",
    "# Calculate lateral PSF for Cy5 channel\n",
    "fwhm_xy_cy5 = 0.61 * wavelength_cy5 / na\n",
    "# Calculate axial PSF for Cy5 channel\n",
    "fwhm_z_cy5 = 2 * refractive_index_medium * wavelength_cy5 / na**2\n",
    "# Print the result for Cy5 channel\n",
    "print(f\"Lateral (xy) PSF for Cy5 channel: {fwhm_xy_cy5} nm\")\n",
    "print(f\"Axial (z) PSF for Cy5 channel with 60x oil objective: {fwhm_z_cy5} nm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Call Spot detection function (original, expects both channels)\n",
    "\n",
    "# # Code to call the spot detection function. \n",
    "# voxel_size = (1448, 450, 450)   # Microscope pixel size Z,Y,X\n",
    "# spot_radius_ch0 = (1409, 340, 340)  # PSF Z,Y,X\n",
    "# spot_radius_ch1 = (1283, 310, 310)  # PSF Z,Y,X\n",
    "\n",
    "# # This is creating a list of lists to store the quantification for all images. \n",
    "# list_all_spots_in_each_cell_ch0 = []\n",
    "# list_all_clusters_in_each_cell_ch0 = []\n",
    "# list_all_spots_in_each_cell_ch1 = []\n",
    "# list_all_clusters_in_each_cell_ch1 = []\n",
    "\n",
    "# # Iterate through all_image_stacks and call spot detection with the appropriate arguments\n",
    "# for i, (stack_image, output_directory, subdirectory) in enumerate(zip(all_image_stacks, image_output_directories, subdirectories)):\n",
    "#     image_colors = stack_image[0]\n",
    "\n",
    "#     rna_ch0 = image_colors[0, :, :, :]  # [Z, Y, X, C]\n",
    "#     rna_channel = Cy5\n",
    "#     _, _, list_spots_in_each_cell_ch0, list_clusters_in_each_cell_ch0 = spot_detection(\n",
    "#         rna_ch0, voxel_size, spot_radius_ch0, list_all_masks_cyto[i], output_directory, subdirectory\n",
    "#     )\n",
    "\n",
    "#     rna_ch1 = image_colors[1, :, :, :]  # [Z, Y, X, C]\n",
    "#     rna_channel = mCherry\n",
    "#     _, _, list_spots_in_each_cell_ch1, list_clusters_in_each_cell_ch1 = spot_detection(\n",
    "#         rna_ch1, voxel_size, spot_radius_ch1, list_all_masks_cyto[i], output_directory, subdirectory\n",
    "#     )\n",
    "\n",
    "#     # Append the results to the corresponding lists\n",
    "#     list_all_spots_in_each_cell_ch0.append(list_spots_in_each_cell_ch0)\n",
    "#     list_all_clusters_in_each_cell_ch0.append(list_clusters_in_each_cell_ch0)\n",
    "#     list_all_spots_in_each_cell_ch1.append(list_spots_in_each_cell_ch1)\n",
    "#     list_all_clusters_in_each_cell_ch1.append(list_clusters_in_each_cell_ch1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to call the spot detection function. \n",
    "voxel_size = (1448, 450, 450)   # Microscope pixel size Z,Y,X\n",
    "spot_radius_ch0 = (1006, 287, 287)  # PSF Z,Y,X\n",
    "spot_radius_ch1 = (1283, 262, 262)  # PSF Z,Y,X\n",
    "\n",
    "# Initialize lists to store quantification for all images.\n",
    "list_all_spots_in_each_cell_ch0 = []\n",
    "list_all_clusters_in_each_cell_ch0 = []\n",
    "list_all_spots_in_each_cell_ch1 = []\n",
    "list_all_clusters_in_each_cell_ch1 = []\n",
    "\n",
    "# Iterate through image stacks and call spot detection\n",
    "for i, (stack_image, output_directory, subdirectory) in enumerate(zip(all_image_stacks, image_output_directories, subdirectories)):\n",
    "    image_colors = stack_image[0]\n",
    "    \n",
    "    # Check for Cy5 (Channel 0)\n",
    "    if Cy5 is not None and image_colors[0, :, :, :] is not None:\n",
    "        rna_ch0 = image_colors[0, :, :, :]  # Extract Cy5 channel [Z, Y, X]\n",
    "        rna_channel = Cy5\n",
    "        _, _, list_spots_in_each_cell_ch0, list_clusters_in_each_cell_ch0 = spot_detection(\n",
    "            rna_ch0, voxel_size, spot_radius_ch0, list_all_masks_cyto[i], output_directory, subdirectory\n",
    "        )\n",
    "        list_all_spots_in_each_cell_ch0.append(list_spots_in_each_cell_ch0)\n",
    "        list_all_clusters_in_each_cell_ch0.append(list_clusters_in_each_cell_ch0)\n",
    "    \n",
    "    # Check for mCherry (Channel 1)\n",
    "    if mCherry is not None and image_colors[1, :, :, :] is not None:\n",
    "        rna_ch1 = image_colors[1, :, :, :]  # Extract mCherry channel [Z, Y, X]\n",
    "        rna_channel = mCherry\n",
    "        _, _, list_spots_in_each_cell_ch1, list_clusters_in_each_cell_ch1 = spot_detection(\n",
    "            rna_ch1, voxel_size, spot_radius_ch1, list_all_masks_cyto[i], output_directory, subdirectory\n",
    "        )\n",
    "        list_all_spots_in_each_cell_ch1.append(list_spots_in_each_cell_ch1)\n",
    "        list_all_clusters_in_each_cell_ch1.append(list_clusters_in_each_cell_ch1)\n",
    "    \n",
    "    # Display the plots if needed\n",
    "    plt.show()\n",
    "\n",
    "# After this loop, you will have `list_all_spots_in_each_cell_ch0`, `list_all_clusters_in_each_cell_ch0`, \n",
    "# `list_all_spots_in_each_cell_ch1`, and `list_all_clusters_in_each_cell_ch1` filled with data for all images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Call spot detection function and store counts in list only if the channels exist\n",
    "\n",
    "# # Code to call the spot detection function. \n",
    "# voxel_size = (1448, 450, 450)   # Microscope pixel size Z,Y,X\n",
    "# spot_radius_ch0 = (1006, 287, 287)  # PSF Z,Y,X\n",
    "# spot_radius_ch1 = (1283, 310, 310)  # PSF Z,Y,X #1283, 262, 262\n",
    "\n",
    "# # This is creating a list of lists to store the quantification for all images. \n",
    "# list_all_spots_in_each_cell_ch0 = []\n",
    "# list_all_clusters_in_each_cell_ch0 = []\n",
    "# list_all_spots_in_each_cell_ch1 = []\n",
    "# list_all_clusters_in_each_cell_ch1 = []\n",
    "\n",
    "# # Iterate through all_image_stacks and call spot detection with the appropriate arguments\n",
    "# for i, (stack_image, output_directory, subdirectory) in enumerate(zip(all_image_stacks, image_output_directories, subdirectories)):\n",
    "#     image_colors = stack_image[0]\n",
    "    \n",
    "#     if Cy5 is not None and image_colors[0,:,:,:] is not None:\n",
    "#         rna_ch0 = image_colors[0, :, :, :]  # [Z, Y, X, C]\n",
    "#         rna_channel = Cy5\n",
    "#         _, _, list_spots_in_each_cell_ch0, list_clusters_in_each_cell_ch0 = spot_detection(\n",
    "#             rna_ch0, voxel_size, spot_radius_ch0, list_all_masks_cyto[i], output_directory, subdirectory\n",
    "#         )\n",
    "\n",
    "#     if mCherry is not None and image_colors[1,:,:,:] is not None:\n",
    "#         rna_ch1 = image_colors[1, :, :, :]  # [Z, Y, X, C]\n",
    "#         rna_channel = mCherry\n",
    "#         _, _, list_spots_in_each_cell_ch1, list_clusters_in_each_cell_ch1 = spot_detection(\n",
    "#             rna_ch1, voxel_size, spot_radius_ch1, list_all_masks_cyto[i], output_directory, subdirectory\n",
    "#         )\n",
    "           \n",
    "#     # Save in each image_output_directory\n",
    "#     image_output_directory = image_output_directories[i]\n",
    "#     subdirectory = subdirectories[i]\n",
    "#     plt.show()\n",
    " \n",
    "\n",
    "#     # Append the results to the corresponding lists\n",
    "#     if 'list_spots_in_each_cell_ch0' in locals() and list_spots_in_each_cell_ch0 is not None:\n",
    "#         list_all_spots_in_each_cell_ch0.append(list_spots_in_each_cell_ch0)\n",
    "        \n",
    "#     if 'list_clusters_in_each_cell_ch0' in locals() and list_clusters_in_each_cell_ch0 is not None:\n",
    "#         list_all_clusters_in_each_cell_ch0.append(list_clusters_in_each_cell_ch0)\n",
    "    \n",
    "#     if 'list_spots_in_each_cell_ch1' in locals() and list_spots_in_each_cell_ch1 is not None:\n",
    "#         list_all_spots_in_each_cell_ch1.append(list_clusters_in_each_cell_ch1)\n",
    "        \n",
    "#     if 'list_clusters_in_each_cell_ch1' in locals() and list_clusters_in_each_cell_ch1 is not None:\n",
    "#         list_all_clusters_in_each_cell_ch1.append(list_clusters_in_each_cell_ch1)\n",
    "\n",
    "#     list_all_spots_in_each_cell_ch0.append(list_spots_in_each_cell_ch0)\n",
    "#     list_all_clusters_in_each_cell_ch0.append(list_clusters_in_each_cell_ch0)\n",
    "#     list_all_spots_in_each_cell_ch1.append(list_spots_in_each_cell_ch1)\n",
    "#     list_all_clusters_in_each_cell_ch1.append(list_clusters_in_each_cell_ch1)\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total abundance csv\n",
    "# Calculate the sum of each list\n",
    "total_spots_ch0 = [sum(sublist) for sublist in list_all_spots_in_each_cell_ch0]\n",
    "total_clusters_ch0 = [sum(sublist) for sublist in list_all_clusters_in_each_cell_ch0]\n",
    "total_spots_ch1 = [sum(sublist) for sublist in list_all_spots_in_each_cell_ch1]\n",
    "total_clusters_ch1 = [sum(sublist) for sublist in list_all_clusters_in_each_cell_ch1]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df_quantification = pd.DataFrame()\n",
    "\n",
    "# Initialize empty lists for image_names and all_data\n",
    "image_names = []\n",
    "all_data = []\n",
    "\n",
    "# Iterate over subdirectory_paths\n",
    "for img_index, subdirectory_path in enumerate(subdirectory_paths):\n",
    "    image_name = subdirectory_path.split(os.path.sep)[-1]\n",
    "    image_names.append(image_name)\n",
    "\n",
    "    data = {\n",
    "        'Image ID': image_names[img_index],\n",
    "        f'{Cy5} molecules': total_spots_ch0[img_index],\n",
    "        f'{mCherry} molecules': total_spots_ch1[img_index],\n",
    "        f'{Cy5} clusters': total_clusters_ch0[img_index],\n",
    "        f'{mCherry} clusters': total_clusters_ch1[img_index],\n",
    "    }\n",
    "\n",
    "    # Append data to the list\n",
    "    all_data.append(data)\n",
    "\n",
    "# Convert the list of data dictionaries to a DataFrame\n",
    "df_quantification = pd.DataFrame(all_data)\n",
    "\n",
    "# Set the title attribute (optional)\n",
    "df_quantification.title = folder_name\n",
    "\n",
    "# Save as .csv\n",
    "quantification_output = os.path.join(output_directory, 'quantification_' + folder_name + '.csv')\n",
    "df_quantification.to_csv(quantification_output, index=False)\n",
    "\n",
    "# Optionally, you can assign path_output to quantification_output if needed\n",
    "path_output = quantification_output\n",
    "\n",
    "# Print the title\n",
    "print(f'Experiment ID: {folder_name}\\n')\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "df_quantification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Collect spot detection output in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the given data\n",
    "list_all_spots_ch0 = total_spots_ch0\n",
    "list_all_spots_ch1 = total_spots_ch1\n",
    "\n",
    "data = {\n",
    "    'mRNA': [Cy5] * len(list_all_spots_ch0) + [mCherry] * len(list_all_spots_ch1),\n",
    "    'number_spots': list_all_spots_ch0 + list_all_spots_ch1\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a violin plot, boxplot, and swarmplot\n",
    "sns.violinplot(x=\"mRNA\", y=\"number_spots\", hue=\"mRNA\", data=df, inner=None, color=\"lightgray\", density_norm='width', palette=\"pastel\", legend=False)\n",
    "sns.boxplot(x=\"mRNA\", y=\"number_spots\", data=df, color=\"gray\", width=0.3, showfliers=False)\n",
    "sns.swarmplot(x=\"mRNA\", y=\"number_spots\", data=df, color=\"black\", size=4, alpha=0.7)\n",
    "\n",
    "# Include folder_name in the title\n",
    "plt.title(f\"mRNA Abundance in {folder_name}\")\n",
    "\n",
    "# Customize axis labels\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Total Number of mRNA Spots\")\n",
    "\n",
    "# Save as .png\n",
    "# Define the output path before saving the PNG\n",
    "violin_output = os.path.join(output_directory, f'violin_{folder_name}.png')\n",
    "plt.savefig(violin_output)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis of Special Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_all_spots_in_each_cell_ch0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create html report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import os\n",
    "\n",
    "def collect_png_files(directory):\n",
    "    png_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.png'):\n",
    "            png_files.append(os.path.join(directory, file))\n",
    "    return png_files\n",
    "\n",
    "def create_pdf_report(pdf_filename, image_filenames):\n",
    "    c = canvas.Canvas(pdf_filename, pagesize=letter)\n",
    "\n",
    "    # Add images to the PDF\n",
    "    y_offset = 50\n",
    "    for image_filename in image_filenames:\n",
    "        c.drawInlineImage(image_filename, x=50, y=y_offset, width=500, height=300)\n",
    "        y_offset += 320  # Adjust the y_offset to leave space between images\n",
    "\n",
    "    c.save()\n",
    "\n",
    "# Directory path\n",
    "directory_path = image_output_directory\n",
    "\n",
    "# Get PNG files in the directory\n",
    "png_files = collect_png_files(directory_path)\n",
    "\n",
    "# PDF filename\n",
    "pdf_filename = \"output_report.pdf\"\n",
    "\n",
    "# Create PDF report with embedded images\n",
    "create_pdf_report(pdf_filename, png_files)\n",
    "\n",
    "print(f\"PDF report generated at: {pdf_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigfish_env",
   "language": "python",
   "name": "bigfish_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
